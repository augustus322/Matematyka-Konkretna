{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666fdbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      " human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making, and competing at the highest level in strategic g\n",
      "-----\n",
      "iter 8500, loss 0.104995\n",
      "Osiągnięto dokładność <= 0.1\n",
      "Trening zakończony.\n"
     ]
    }
   ],
   "source": [
    "# Zajęcie 5: Metoda BPTT dla sieci LSTM\n",
    "\n",
    "# Importowanie\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import signal\n",
    "from random import uniform\n",
    "\n",
    "plt.style.use('seaborn-v0_8-white')\n",
    "\n",
    "# Odczytywanie i przetwarzanie danych\n",
    "data = open('zadanie.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "data_size, X_size = len(data), len(chars)\n",
    "print(f\"data has {data_size} characters, {X_size} unique\")\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Stałe i hiperparametry\n",
    "H_size = 50               # Size of the hidden layer\n",
    "T_steps = 50            # Number of time steps (Length of the sequence) used for training\n",
    "learning_rate = 0.15      # Learning rate\n",
    "weight_sd = 0.05           # Standard deviation of weights for initialization\n",
    "z_size = H_size + X_size  # Size of concatenate(H, X) vector\n",
    "\n",
    "# Funkcje aktywacji i pochodne\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y\n",
    "\n",
    "# Parametry\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value          # parameter value\n",
    "        self.d = np.zeros_like(value)  # derivative\n",
    "        self.m = np.zeros_like(value)  # momentum for AdaGrad\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f', np.zeros((H_size, 1)))\n",
    "        self.W_i = Param('W_i', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i', np.zeros((H_size, 1)))\n",
    "        self.W_C = Param('W_C', np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C', np.zeros((H_size, 1)))\n",
    "        self.W_o = Param('W_o', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o', np.zeros((H_size, 1)))\n",
    "        # For final layer to predict the next character\n",
    "        self.W_v = Param('W_v', np.random.randn(X_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v', np.zeros((X_size, 1)))\n",
    "    \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "                self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "\n",
    "parameters = Parameters()\n",
    "\n",
    "# Obliczanie do przodu\n",
    "def forward(x, h_prev, C_prev, p=parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    \n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "    \n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v))  # softmax\n",
    "    \n",
    "    return z, f, i, C_bar, C, o, h, v, y\n",
    "\n",
    "# Obliczanie wstecz\n",
    "def backward(target, dh_next, dC_next, C_prev, z, f, i, C_bar, C, o, h, v, y, p=parameters):\n",
    "    assert z.shape == (X_size + H_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "    \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "    \n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "    \n",
    "    dh = np.dot(p.W_v.v.T, dv)\n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "    \n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "    \n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "    \n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "    \n",
    "    dz = (np.dot(p.W_f.v.T, df) + \n",
    "          np.dot(p.W_i.v.T, di) + \n",
    "          np.dot(p.W_C.v.T, dC_bar) + \n",
    "          np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev\n",
    "\n",
    "# Pomocnicze funkcje\n",
    "def clear_gradients(params=parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)\n",
    "\n",
    "def clip_gradients(params=parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)\n",
    "\n",
    "# Forward i backward dla całej sekwencji\n",
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    x_s, z_s, f_s, i_s, C_bar_s, C_s, o_s, h_s, v_s, y_s = (\n",
    "        {}, {}, {}, {}, {}, {}, {}, {}, {}, {})\n",
    "    \n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # Forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t], C_bar_s[t], \n",
    "         C_s[t], o_s[t], h_s[t], v_s[t], y_s[t]) = forward(x_s[t], h_s[t-1], C_s[t-1])\n",
    "        \n",
    "        loss += -np.log(y_s[t][targets[t], 0])\n",
    "    \n",
    "    clear_gradients()\n",
    "    dh_next = np.zeros_like(h_s[0])\n",
    "    dC_next = np.zeros_like(C_s[0])\n",
    "    \n",
    "    # Backward pass\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dh_next, dC_next = backward(\n",
    "            target=targets[t], \n",
    "            dh_next=dh_next, \n",
    "            dC_next=dC_next, \n",
    "            C_prev=C_s[t-1],\n",
    "            z=z_s[t], \n",
    "            f=f_s[t], \n",
    "            i=i_s[t], \n",
    "            C_bar=C_bar_s[t],\n",
    "            C=C_s[t], \n",
    "            o=o_s[t], \n",
    "            h=h_s[t], \n",
    "            v=v_s[t],\n",
    "            y=y_s[t]\n",
    "        )\n",
    "    \n",
    "    clip_gradients()\n",
    "    return loss, h_s[len(inputs)-1], C_s[len(inputs)-1]\n",
    "\n",
    "# Generowanie tekstu\n",
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "    \n",
    "    return indexes\n",
    "\n",
    "# Status i aktualizacja\n",
    "def update_status(inputs, h_prev, C_prev):\n",
    "    global plot_iter, plot_loss, smooth_loss, iteration\n",
    "    \n",
    "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
    "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "    \n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-----\\n%s\\n-----\" % txt)\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))\n",
    "\n",
    "def update_parameters(params=parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))\n",
    "\n",
    "# Opóźnione przerwanie klawiatury\n",
    "class DelayedKeyboardInterrupt:\n",
    "    def __enter__(self):\n",
    "        self.signal_received = False\n",
    "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
    "    \n",
    "    def handler(self, sig, frame):\n",
    "        self.signal_received = (sig, frame)\n",
    "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "        if self.signal_received:\n",
    "            self.old_handler(*self.signal_received)\n",
    "\n",
    "# Inicjalizacja zmiennych treningowych\n",
    "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
    "iteration, pointer = 0, 0\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))\n",
    "\n",
    "# Pętla treningowa\n",
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            if pointer + T_steps >= len(data) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "            \n",
    "            inputs = [char_to_idx[ch] for ch in data[pointer: pointer + T_steps]]\n",
    "            targets = [char_to_idx[ch] for ch in data[pointer + 1: pointer + T_steps + 1]]\n",
    "            \n",
    "            loss, g_h_prev, g_C_prev = forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            if smooth_loss <= 0.1:\n",
    "                print(\"Osiągnięto dokładność <= 0.1\")\n",
    "                break\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "            \n",
    "            update_parameters()\n",
    "            \n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "            \n",
    "            pointer += T_steps\n",
    "            iteration += 1     \n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break\n",
    "\n",
    "print(\"Trening zakończony.\")\n",
    "\n",
    "# Sprawdzanie gradientu (opcjonalne)\n",
    "def calc_numerical_gradient(param, idx, delta, inputs, targets, h_prev, C_prev):\n",
    "    old_val = param.v.flat[idx]\n",
    "    \n",
    "    param.v.flat[idx] = old_val + delta\n",
    "    loss_plus_delta, _, _ = forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    param.v.flat[idx] = old_val - delta\n",
    "    loss_mins_delta, _, _ = forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    param.v.flat[idx] = old_val\n",
    "    \n",
    "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
    "    grad_numerical = np.clip([grad_numerical], -1, 1)[0]\n",
    "    \n",
    "    return grad_numerical\n",
    "\n",
    "def gradient_check(num_checks, delta, inputs, targets, h_prev, C_prev):\n",
    "    _, _, _ = forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    for param in parameters.all():\n",
    "        d_copy = np.copy(param.d)\n",
    "        \n",
    "        for i in range(num_checks):\n",
    "            rnd_idx = int(uniform(0, param.v.size))\n",
    "            \n",
    "            grad_numerical = calc_numerical_gradient(param, rnd_idx, delta, inputs, targets, h_prev, C_prev)\n",
    "            grad_analytical = d_copy.flat[rnd_idx]\n",
    "            \n",
    "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
    "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
    "            \n",
    "            if rel_error > 1e-06:\n",
    "                print('%s (%e, %e) => %e' % (param.name, grad_numerical, grad_analytical, rel_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
